{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLLVM for longitudinal data: a pytorch implementation\n",
    "\n",
    "We consider the following model\n",
    "\n",
    "TODO:\n",
    "* ~~learn the nuisance parameters! To learn phi, make the encoder learn the zhats **before** AR(1) is applied, and take the gradient of the decoder. that is, make the decoder have phi as a parameter, and same for var_mu!~~ \n",
    "* ~~allow for gaussian and binary data~~ \n",
    "* ~~Compute the gradient that define the model~~\n",
    "* allow for missing values and impute them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ## Model Specification\n",
    "\n",
    "Let  $y_{i1t},y_{i2t},\\ldots,y_{ipt}$  be a set of $p$ response or observed variables at time $t,\\ t=1,\\ldots,T$ for  individual $i,\\ i=1,\\ldots,n$. Let $\\mathbf{x}_{it}$ be a set of observed $k$-dimensional covariates at time $t,\\ t=1,\\ldots,T$.\n",
    "\n",
    "Models for multivariate longitudinal data have to account for the three sources of variability\n",
    "present in the data, that is (i) cross-sectional associations between the responses at a particular time point, (ii) cross-lagged\n",
    "associations between different responses at different occasions, and  (iii) the association between repeated measures of the same response\n",
    "over time. The first source of variability is accounted for\n",
    "a time-dependent latent variable $z_{i1}, z_{i2},\\ldots,z_{iT}$. Modeling the temporal evolution of the latent variable accounts for the cross-lagged associations between different responses over time.\n",
    "The third source of variability can be accounted for a set of item-specific random effects $\\mathbf{u}_{i}=(u_{i1}, \\ldots, u_{ip})'$.\n",
    "\n",
    "According to the GLLVM framework we have\n",
    "\n",
    "\\begin{align*}\n",
    "   \\nonumber y_{ijt}|\\mu_{ijt} &\\sim \\mathcal{F}_j(y_{ijt}\\vert \\mu_{ijt}, \\tau_j)\\\\\n",
    "   \\mu_{ijt}&=  g_j(\\eta_{ijt})=g_j(\\beta_{0jt} + \\mathbf{x}_{i}^{\\top}\\boldsymbol \\beta_{jt} + z_{it}^{\\top}\\lambda_{jt}+u_{ij}\\sigma_{u_j})\\\\ %  \\label{eqn:GLLVM-model2}\n",
    "\\end{align*}\n",
    "where $g_j(\\cdot),j=1,\\ldots,p$ is a known {\\it link function}, $\\eta_{ijt}=\\beta_{0jt} + \\mathbf{x}_{i}^{\\top}\\boldsymbol \\beta_{jt} + z_{it}^{\\top}\\lambda_{jt}+u_{ij},i=1,\\ldots,n,j=1,\\ldots,p, t=1,\\ldots,T$ is the {\\it linear predictor},  and $\\mathcal{F}_j(y_{ijt}\\vert \\eta_{ijt}, \\tau_j)$ denotes a distribution from the exponential family with mean $\\mu_{ijt}$ and response variable-specific dispersion parameter $\\tau_j$. \\vspace{5pt}\\\\\n",
    "The dynamics of the latent variable over time is modelled through a non-stationary autoregressive model of first order\n",
    "\n",
    "\\begin{equation*}\n",
    "z_{it}=\\phi z_{i,t-1} + \\delta_{it}\n",
    "\\end{equation*}%\n",
    "where  $z_{i1}\\sim N(0,\\sigma^2_{1})$ and $\\delta_{it}\\sim N(0,1)$.  Moreover, we assume the random effects independent of the latent variable and their common distribution $\\mathbf{u}_{i}\\sim N_p(\\mathbf{0}, \\boldsymbol I)$.\n",
    "\n",
    "\n",
    "### Changes I propose:\n",
    "\n",
    "allow x to depend on time.\n",
    "\n",
    "\n",
    "## Measurement invariance\n",
    "\n",
    "The  latent variable $z_{it}$ has to be the same (same meaning) across occasions.\n",
    "Thus the measurement invariance assumption has to be tested on the data, that is \n",
    "all the measurement parameters  are invariant across occasions, that is $$\\beta_{0jt}=\\beta_{0j} \\ \\textrm{and } \\ \\lambda_{jt}=\n",
    "\\lambda_{j},$$ for all $t$, $t=1, \\ldots, T$ and for all $j$, $j=1,\\ldots, p$.\n",
    "Under this assumption, the model is more parsimonious  and avoids some possible identification problem that might arise with\n",
    "increasing the number of time points.\n",
    "\n",
    "To ensure identification of the model, one necessary condition is that the latent variable has a scale and an origin. %When measurement\n",
    "%invariance of loadings and intercepts is imposed,\n",
    "Scale for  $z_{it}$  can be provided either by fixing one loading at a nonzero value or by\n",
    "fixing the factor variance at a nonzero value. In presence of longitudinal data, the same loading is fixed equal to one at each occasion.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast prototyping using Pytorch\n",
    "\n",
    "We model each observation as a tuple of dimension `(T, p)`, common across individuals. Individuals constitute independent observations, which yields the tensor structure `(n, T, q)`. The time dimension `T` appears in the first dimension since it allows for seamless tensor products of the type `(n, T, q) (q, p)`.\n",
    "\n",
    "We need\n",
    "\n",
    "* A model that defines the generative process\n",
    "* A loss function which, upon taking the derivative, re-creates the estimating equations\n",
    "* A way to compute the latent variables. For now, we will use a neural network. Later, we can implement the real function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the preprocessed data\n",
    "data = np.load(\"../data/HRS/HRS_3Darray.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "The data has been pre-processed as a 3D array with dimensions given by $(n, k+p, T)$.\n",
    "\n",
    "The final array is a 3D array of shape (n, k+p, T), where \n",
    "* n is the number of observations, \n",
    "* k is the number of covariates,\n",
    "* p is the number of responses to be modeled by the latent variables,\n",
    "* T is the number of time observations\n",
    "\n",
    "The variables are ordered as follows:\n",
    "\n",
    "**Covariates**\n",
    "\n",
    "- age (covariate)\n",
    "- gender (covariate)\n",
    "- education (covariate)\n",
    "\n",
    "**Responses**\n",
    "\n",
    "- month (binary)\n",
    "- day (binary)\n",
    "- year (binary)\n",
    "- day_week (binary)\n",
    "- paper (binary)\n",
    "- cactus (binary)\n",
    "- president (binary)\n",
    "- vice_president (binary)\n",
    "- serie_7 (count)\n",
    "- backwards (ordinal)\n",
    "- recall_immediate (count)\n",
    "- recall_delayed (count)\n",
    "\n",
    "The binary random variables are modelled conditionally with a logistic regression; the ordinal variables with an ordinal logistic regression; the counts with poisson regression.\n",
    "\n",
    "The ordinal responses require an intercept for each level, or \"cutpoints\". In our case, we model this by hard-coding the intercept, but it should be made more general. We assume the effect of the covariates is constant across categories, resulting in a proportional odds model.\n",
    "\n",
    "We need to split the ordinal \"backwards\" into variable into two new variables: backwards_1 and backwards_2. The responses become:\n",
    "\n",
    "**Covariates**\n",
    "\n",
    "- 0: age (covariate)\n",
    "- 1: gender (covariate)\n",
    "- 2: education (covariate)\n",
    "\n",
    "**Responses**\n",
    "\n",
    "- 0: month (binary)\n",
    "- 1: day (binary)\n",
    "- 2: year (binary)\n",
    "- 3: day_week (binary)\n",
    "- 4: paper (binary)\n",
    "- 5: cactus (binary)\n",
    "- 6: president (binary)\n",
    "- 7: vice_president (binary)\n",
    "- 8: serie_7 (count)\n",
    "- 9: backwards_1 (dummy)\n",
    "- 10: backwards_2 (dummy)\n",
    "- 11: recall_immediate (count)\n",
    "- 12: recall_delayed (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.0"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the backwards_1 and backwards_2 dummies:\n",
    "backwards_1 = (data[:,12]==1)\n",
    "backwards_2 = (data[:,12, np.newaxis]==2)\n",
    "\n",
    "# insert them\n",
    "data[:,12] = backwards_1\n",
    "data = np.concatenate([data[:,:12], backwards_2, data[:,12:]], axis=1)\n",
    "\n",
    "np.nanmax(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate covariates and responses, and prepare the torch tensors\n",
    "\n",
    "data = np.transpose(data, (0,2,1))\n",
    "data_true = {\n",
    "    'x': torch.from_numpy(data[:,:,:3]).float(),\n",
    "    'y': torch.from_numpy(data[:,:,3:]).float()\n",
    "}\n",
    "\n",
    "response_types = {\n",
    "    'binary': [0,1,2,3,4,5,6,7],\n",
    "    'ordinal': [9, 10],\n",
    "    'counts': [8, 11, 12]\n",
    "}\n",
    "\n",
    "link = {\n",
    "    'binary' : lambda x: torch.logit(x),\n",
    "    'ordinal': lambda x: torch.logit(x),\n",
    "    'counts': lambda x: torch.log(x)\n",
    "}\n",
    "\n",
    "\n",
    "linkinv_decoder = {\n",
    "    'binary': lambda x: 1/(1+torch.exp(-x)),\n",
    "    'ordinal': lambda x: 1/(1+torch.exp(-x)),\n",
    "    'counts': lambda x: torch.exp(x) # see below remarks for the standardization of the \"counts\"\n",
    "}\n",
    "\n",
    "response_transform = {\n",
    "    'binary' : lambda x: 2*x - 1,\n",
    "    'ordinal': lambda x: 2*x - 1,\n",
    "    'counts': lambda x: torch.log(x+1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x: torch.Size([1000, 9, 3])\n",
      "shape of y: torch.Size([1000, 9, 13])\n"
     ]
    }
   ],
   "source": [
    "# The shape must be (n, T, p)\n",
    "\n",
    "for key, value in data_true.items():\n",
    "    print(f'shape of {key}: {value.shape}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 1000 observations, 3 covariates, 13 responses, 9 time periods, 1 latent variable per time period.\n"
     ]
    }
   ],
   "source": [
    "n = data_true['x'].shape[0]\n",
    "k = data_true['x'].shape[2]\n",
    "p = data_true['y'].shape[2]\n",
    "T = data_true['y'].shape[1]\n",
    "q = 1\n",
    "\n",
    "print(f'Data with {n} observations, {k} covariates, {p} responses, {T} time periods, {1} latent variable per time period.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  dealing with missing data\n",
    "We deal with missing data in two ways:\n",
    "\n",
    "* The missing values are iteratively imputed by their conditional mean.\n",
    "* To compute the Z, we use the imputed means.\n",
    "* To compute the parameters, we use the imputed means and estimated Z but *provide the mask* so that the update does not take the missing values into account in the computation of the gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = {}\n",
    "\n",
    "mask['x'] = torch.isnan(data_true['x'])\n",
    "mask['y'] = torch.isnan(data_true['y'])\n",
    "\n",
    "data_true['x'][mask['x']] = 0\n",
    "data_true['y'][mask['y']] = 0\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data standardization\n",
    "\n",
    "To improve numerical stability, we transform the counts as $y\\to \\log(y+1)$. This is reflected in the sampling mechanics. As a result, we use the identity as a link function for the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical stability issues for poisson data\n",
    "\n",
    "data_true['x'][:,:,0] = data_true['x'][:,:,0] /100\n",
    "# For numerical stability, we transform the counts (poisson) as y -> log(y+1)\n",
    "# This is reflected in our sampling mechanism so we don't introduce a bias\n",
    "# data_true['y'][:,:,response_types['counts']] = torch.log(data_true['y'][:,:,response_types['counts']] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 9, 3])\n",
      "torch.Size([1000, 9, 13])\n"
     ]
    }
   ],
   "source": [
    "print(data_true['x'].shape)\n",
    "print(data_true['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIMENSIONS_Y = (n, T, p) \n",
    "DIMENSIONS_X = (n, T, k)\n",
    "DIMENSIONS_Z = (n, T, q)\n",
    "DIMENSIONS_U = (n, 1, p)\n",
    "\n",
    "# TODO: refactor to have a module of two modules: encoder and decoder\n",
    "class GLLVM_longitudinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.var_u = nn.Parameter(torch.ones((1,1,p)))\n",
    "        self.phi = nn.Parameter(torch.ones(1))*.05\n",
    "\n",
    "    def encoder_fit(self, x, y, z, u, epochs=100, verbose=False):\n",
    "        y = y.clone()\n",
    "        with torch.no_grad():\n",
    "            for response_type, response_id in response_types.items():\n",
    "                y[:,:,response_id] = response_transform[response_type](y[:,:,response_id])\n",
    "        # Fit the encoder\n",
    "        encoder_loss = nn.MSELoss()\n",
    "        encoder_opt = torch.optim.Adam(self.encoder.parameters())\n",
    "        for epoch in range(epochs):\n",
    "            (zhat, uhat) = self.encoder(x, y)\n",
    "            loss = encoder_loss(zhat, z) + encoder_loss(uhat, u) # TODO: check that it's correct,maybe Z needs to be weighed more than u\n",
    "            if verbose:\n",
    "                print(f\"\\nEpoch {epoch}/{epochs}, loss={loss}, max_ :hat {torch.max(zhat)}\")\n",
    "            loss.backward()\n",
    "            encoder_opt.step()\n",
    "            encoder_opt.zero_grad()\n",
    "        return loss\n",
    "\n",
    "    def AR(self, d):\n",
    "        z = d.clone()\n",
    "\n",
    "        for t in range(1, z.shape[1]):\n",
    "            z[:,t] = z[:,t] + z[:, t-1].clone() * self.phi  # we need to clone else the gradient wants to pass through it\n",
    "        return z\n",
    "    \n",
    "    def sample(self, n, x=None, u=None, d=None):\n",
    "        with torch.no_grad():\n",
    "            \"\"\"Sample a longitudinal GLLVM, potentially with z, u, and d(elta), and return (x, u, d, y)\"\"\"\n",
    "\n",
    "            if x is None:\n",
    "                Warning(\"x was set to None for sampling. This is usually unwanted unless k=0.\")\n",
    "                x = torch.randn((n, T, k))\n",
    "            if u is None:\n",
    "                u = torch.randn((n, 1, p))\n",
    "            if d is None:\n",
    "                d = torch.randn((n, T, q))\n",
    "\n",
    "            # for normal responses: eps = torch.randn((n, T, p)) * torch.sqrt(self.decoder.var_y)\n",
    "            z = self.AR(d)\n",
    "            u = u * torch.sqrt(self.var_u)\n",
    "\n",
    "            y, linpar = self.decoder(x, z, u) # decoder gives the expectation\n",
    "            for response_type, response_id in response_types.items():\n",
    "                if response_type == \"binary\":\n",
    "                    y[:,:,response_id] = torch.bernoulli(y[:,:,response_id])\n",
    "                elif response_type == \"ordinal\":\n",
    "                    y_ordinal = y[:,:,response_id]\n",
    "                    # draw one uniform for the whole vector\n",
    "                    random = torch.rand((*y_ordinal.shape[0:2], 1)) \n",
    "                    # compare with the cumulative probabilities\n",
    "                    ordinal = torch.sum(random < y_ordinal, axis=2)\n",
    "                    ordinal = torch.nn.functional.one_hot(ordinal).squeeze().float()\n",
    "                    ordinal = ordinal[:,:,1:] # discard the first column of the one_hot encoding, as it is superfluous (as a 0)\n",
    "                    y[:,:,response_id] = ordinal\n",
    "                elif response_type == \"counts\":\n",
    "                    y[:,:,response_id] = torch.poisson(y[:,:,response_id]).clamp(0, 20)\n",
    "\n",
    "                     \n",
    "            return {\"x\":x, \"u\":u, \"d\":d, \"y\":y, \"z\":z, \"linpar\":linpar}\n",
    "    \n",
    "    def impute(self, x, y, mask, nsteps=10):\n",
    "        \"\"\" Impute the missing values provided by the mask (True is missing) and return x imputed\"\"\"\n",
    "        for _ in range(nsteps):\n",
    "            d, u = self.encoder(x,y)\n",
    "            y_decoded, _ = self.decoder(x,d,u)\n",
    "            y[mask] = y_decoded[mask]\n",
    "        return y\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    # Yields the expectation\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # decoder part (our parameters of interest)\n",
    "        self.wz = nn.Parameter(torch.randn((q, p)))\n",
    "        self.wx = nn.Parameter(torch.randn((T, k, p)))\n",
    "        self.bias = nn.Parameter(torch.zeros((1, T, p)))\n",
    "\n",
    "\n",
    "        # nuisance parameters\n",
    "\n",
    "        self.var_y = nn.Parameter(torch.ones((1,1,p))) # this appears in the loss function, but we know all of them to be 1 by design\n",
    "\n",
    "    # decoding (computing the conditional mean)\n",
    "    def forward(self, x, z, u):\n",
    "\n",
    "        xwx = (x.unsqueeze(2) @ self.wx).squeeze() # see section \"details of tensorproducts\"\n",
    "        zwz = (z.unsqueeze(2) @ self.wz).squeeze()\n",
    "        # for the ordinal variables:\n",
    "        linpar = self.bias + xwx + zwz + u \n",
    "\n",
    "        # Apply the inverse link to get the conditional expectation\n",
    "        yhat  = torch.zeros_like(linpar)\n",
    "        for response_type, response_id in response_types.items():\n",
    "            yhat[:,:,response_id] = linkinv_decoder[response_type](linpar[:,:,response_id])\n",
    "        # Transform the \n",
    "        return yhat, linpar\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # encoder part\n",
    "        # input dimension is T * (p+k)... we buuild a fully connected layer but it isn't necessary \n",
    "        # output dimension is T*q  + p (for Z and U, respectively)\n",
    "        self.enc_model = nn.Sequential(\n",
    "            nn.Linear(in_features=T*(p+k), out_features = 100),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(in_features=100, out_features = 100),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(in_features=100, out_features = 100),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features = T*q + p)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y, transform_response = False):\n",
    "        if transform_response:\n",
    "            y = y.clone()\n",
    "            with torch.no_grad():\n",
    "                for response_type, response_id in response_types.items():\n",
    "                    y[:,:,response_id] = response_transform[response_type](y[:,:,response_id])\n",
    "\n",
    "        xy = torch.cat([x, y], dim=2).flatten(start_dim=1)\n",
    "        zu = self.enc_model(xy)\n",
    "        return self.split_zu(zu)\n",
    "\n",
    "    def split_zu(self, zu):\n",
    "        #output dimension of size (T*Z), p\n",
    "        z, u = torch.split(zu, [T*q, p], dim=1)\n",
    "        z = z.reshape((z.shape[0], T, q))\n",
    "        u = u.unsqueeze(1)\n",
    "        return (z, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_example = GLLVM_longitudinal()\n",
    "data_example = model_example.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/100, loss=2.129324436187744, max_ :hat 0.8547756671905518\n",
      "\n",
      "Epoch 1/100, loss=2.0755293369293213, max_ :hat 0.7837331891059875\n",
      "\n",
      "Epoch 2/100, loss=2.0287890434265137, max_ :hat 0.7611086964607239\n",
      "\n",
      "Epoch 3/100, loss=1.98760986328125, max_ :hat 0.7453943490982056\n",
      "\n",
      "Epoch 4/100, loss=1.950783371925354, max_ :hat 0.7331778407096863\n",
      "\n",
      "Epoch 5/100, loss=1.9171509742736816, max_ :hat 0.7268040776252747\n",
      "\n",
      "Epoch 6/100, loss=1.8858489990234375, max_ :hat 0.7215969562530518\n",
      "\n",
      "Epoch 7/100, loss=1.8562183380126953, max_ :hat 0.7207502126693726\n",
      "\n",
      "Epoch 8/100, loss=1.8276822566986084, max_ :hat 0.7241119146347046\n",
      "\n",
      "Epoch 9/100, loss=1.7997925281524658, max_ :hat 0.7318204045295715\n",
      "\n",
      "Epoch 10/100, loss=1.7722504138946533, max_ :hat 0.7465075850486755\n",
      "\n",
      "Epoch 11/100, loss=1.7449071407318115, max_ :hat 0.7692789435386658\n",
      "\n",
      "Epoch 12/100, loss=1.7176432609558105, max_ :hat 0.795303463935852\n",
      "\n",
      "Epoch 13/100, loss=1.6903536319732666, max_ :hat 0.8259307742118835\n",
      "\n",
      "Epoch 14/100, loss=1.6629273891448975, max_ :hat 0.8593121767044067\n",
      "\n",
      "Epoch 15/100, loss=1.6353566646575928, max_ :hat 0.8950582146644592\n",
      "\n",
      "Epoch 16/100, loss=1.607590913772583, max_ :hat 0.9326996803283691\n",
      "\n",
      "Epoch 17/100, loss=1.5796787738800049, max_ :hat 0.9709956049919128\n",
      "\n",
      "Epoch 18/100, loss=1.5515689849853516, max_ :hat 1.0103298425674438\n",
      "\n",
      "Epoch 19/100, loss=1.5233464241027832, max_ :hat 1.0501731634140015\n",
      "\n",
      "Epoch 20/100, loss=1.4950273036956787, max_ :hat 1.08953058719635\n",
      "\n",
      "Epoch 21/100, loss=1.4666693210601807, max_ :hat 1.1288081407546997\n",
      "\n",
      "Epoch 22/100, loss=1.4382877349853516, max_ :hat 1.1712419986724854\n",
      "\n",
      "Epoch 23/100, loss=1.4099613428115845, max_ :hat 1.2437999248504639\n",
      "\n",
      "Epoch 24/100, loss=1.3817472457885742, max_ :hat 1.3164567947387695\n",
      "\n",
      "Epoch 25/100, loss=1.353650689125061, max_ :hat 1.3875596523284912\n",
      "\n",
      "Epoch 26/100, loss=1.3257334232330322, max_ :hat 1.4578152894973755\n",
      "\n",
      "Epoch 27/100, loss=1.2980902194976807, max_ :hat 1.5268301963806152\n",
      "\n",
      "Epoch 28/100, loss=1.270782470703125, max_ :hat 1.5947929620742798\n",
      "\n",
      "Epoch 29/100, loss=1.24384605884552, max_ :hat 1.661311149597168\n",
      "\n",
      "Epoch 30/100, loss=1.2173656225204468, max_ :hat 1.726239800453186\n",
      "\n",
      "Epoch 31/100, loss=1.1914587020874023, max_ :hat 1.7886934280395508\n",
      "\n",
      "Epoch 32/100, loss=1.1662232875823975, max_ :hat 1.848837971687317\n",
      "\n",
      "Epoch 33/100, loss=1.1416969299316406, max_ :hat 1.906320571899414\n",
      "\n",
      "Epoch 34/100, loss=1.1178628206253052, max_ :hat 1.9610390663146973\n",
      "\n",
      "Epoch 35/100, loss=1.0947345495224, max_ :hat 2.012831926345825\n",
      "\n",
      "Epoch 36/100, loss=1.0723847150802612, max_ :hat 2.061694383621216\n",
      "\n",
      "Epoch 37/100, loss=1.0508368015289307, max_ :hat 2.106651782989502\n",
      "\n",
      "Epoch 38/100, loss=1.0300997495651245, max_ :hat 2.148221015930176\n",
      "\n",
      "Epoch 39/100, loss=1.0101792812347412, max_ :hat 2.1867880821228027\n",
      "\n",
      "Epoch 40/100, loss=0.9910551309585571, max_ :hat 2.2400574684143066\n",
      "\n",
      "Epoch 41/100, loss=0.9727035760879517, max_ :hat 2.2899115085601807\n",
      "\n",
      "Epoch 42/100, loss=0.9551005363464355, max_ :hat 2.3353018760681152\n",
      "\n",
      "Epoch 43/100, loss=0.9382610321044922, max_ :hat 2.376262664794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/100, loss=0.9221564531326294, max_ :hat 2.4131693840026855\n",
      "\n",
      "Epoch 45/100, loss=0.9067485928535461, max_ :hat 2.447509765625\n",
      "\n",
      "Epoch 46/100, loss=0.8919962644577026, max_ :hat 2.4780077934265137\n",
      "\n",
      "Epoch 47/100, loss=0.8778663873672485, max_ :hat 2.5045018196105957\n",
      "\n",
      "Epoch 48/100, loss=0.8643282651901245, max_ :hat 2.5276408195495605\n",
      "\n",
      "Epoch 49/100, loss=0.8513853549957275, max_ :hat 2.5458130836486816\n",
      "\n",
      "Epoch 50/100, loss=0.8390125036239624, max_ :hat 2.558849334716797\n",
      "\n",
      "Epoch 51/100, loss=0.8271840810775757, max_ :hat 2.5677497386932373\n",
      "\n",
      "Epoch 52/100, loss=0.8158684968948364, max_ :hat 2.5728273391723633\n",
      "\n",
      "Epoch 53/100, loss=0.8050497770309448, max_ :hat 2.5751712322235107\n",
      "\n",
      "Epoch 54/100, loss=0.7947293519973755, max_ :hat 2.5757393836975098\n",
      "\n",
      "Epoch 55/100, loss=0.7848843336105347, max_ :hat 2.5750741958618164\n",
      "\n",
      "Epoch 56/100, loss=0.7754729986190796, max_ :hat 2.573756217956543\n",
      "\n",
      "Epoch 57/100, loss=0.7664714455604553, max_ :hat 2.571523666381836\n",
      "\n",
      "Epoch 58/100, loss=0.75787353515625, max_ :hat 2.568265438079834\n",
      "\n",
      "Epoch 59/100, loss=0.7496517896652222, max_ :hat 2.5642268657684326\n",
      "\n",
      "Epoch 60/100, loss=0.7417894005775452, max_ :hat 2.55936336517334\n",
      "\n",
      "Epoch 61/100, loss=0.7342675924301147, max_ :hat 2.553793430328369\n",
      "\n",
      "Epoch 62/100, loss=0.7270607948303223, max_ :hat 2.548086643218994\n",
      "\n",
      "Epoch 63/100, loss=0.7201492190361023, max_ :hat 2.542858362197876\n",
      "\n",
      "Epoch 64/100, loss=0.713529646396637, max_ :hat 2.5385990142822266\n",
      "\n",
      "Epoch 65/100, loss=0.7071821093559265, max_ :hat 2.535618305206299\n",
      "\n",
      "Epoch 66/100, loss=0.7010760307312012, max_ :hat 2.533106565475464\n",
      "\n",
      "Epoch 67/100, loss=0.6951941251754761, max_ :hat 2.531371831893921\n",
      "\n",
      "Epoch 68/100, loss=0.6895207166671753, max_ :hat 2.530064344406128\n",
      "\n",
      "Epoch 69/100, loss=0.6840505599975586, max_ :hat 2.528064012527466\n",
      "\n",
      "Epoch 70/100, loss=0.6787734031677246, max_ :hat 2.526449203491211\n",
      "\n",
      "Epoch 71/100, loss=0.6736800670623779, max_ :hat 2.5261974334716797\n",
      "\n",
      "Epoch 72/100, loss=0.668755292892456, max_ :hat 2.527435302734375\n",
      "\n",
      "Epoch 73/100, loss=0.6640022397041321, max_ :hat 2.5302536487579346\n",
      "\n",
      "Epoch 74/100, loss=0.6594153642654419, max_ :hat 2.5343334674835205\n",
      "\n",
      "Epoch 75/100, loss=0.6549816727638245, max_ :hat 2.538879632949829\n",
      "\n",
      "Epoch 76/100, loss=0.6506848335266113, max_ :hat 2.5435523986816406\n",
      "\n",
      "Epoch 77/100, loss=0.6465113162994385, max_ :hat 2.5489935874938965\n",
      "\n",
      "Epoch 78/100, loss=0.6424537301063538, max_ :hat 2.554469585418701\n",
      "\n",
      "Epoch 79/100, loss=0.6385049223899841, max_ :hat 2.5603220462799072\n",
      "\n",
      "Epoch 80/100, loss=0.6346567869186401, max_ :hat 2.5665714740753174\n",
      "\n",
      "Epoch 81/100, loss=0.6309034824371338, max_ :hat 2.57413911819458\n",
      "\n",
      "Epoch 82/100, loss=0.6272390484809875, max_ :hat 2.581871509552002\n",
      "\n",
      "Epoch 83/100, loss=0.6236650943756104, max_ :hat 2.5892558097839355\n",
      "\n",
      "Epoch 84/100, loss=0.6201722621917725, max_ :hat 2.595931053161621\n",
      "\n",
      "Epoch 85/100, loss=0.6167574524879456, max_ :hat 2.602168560028076\n",
      "\n",
      "Epoch 86/100, loss=0.6134172081947327, max_ :hat 2.607825994491577\n",
      "\n",
      "Epoch 87/100, loss=0.6101420521736145, max_ :hat 2.6126279830932617\n",
      "\n",
      "Epoch 88/100, loss=0.6069331765174866, max_ :hat 2.617100954055786\n",
      "\n",
      "Epoch 89/100, loss=0.6037887930870056, max_ :hat 2.621314287185669\n",
      "\n",
      "Epoch 90/100, loss=0.6007070541381836, max_ :hat 2.624424934387207\n",
      "\n",
      "Epoch 91/100, loss=0.5976835489273071, max_ :hat 2.626601219177246\n",
      "\n",
      "Epoch 92/100, loss=0.5947173237800598, max_ :hat 2.6277832984924316\n",
      "\n",
      "Epoch 93/100, loss=0.5918087363243103, max_ :hat 2.628195285797119\n",
      "\n",
      "Epoch 94/100, loss=0.588946521282196, max_ :hat 2.6283578872680664\n",
      "\n",
      "Epoch 95/100, loss=0.5861338973045349, max_ :hat 2.6284048557281494\n",
      "\n",
      "Epoch 96/100, loss=0.5833629965782166, max_ :hat 2.6285810470581055\n",
      "\n",
      "Epoch 97/100, loss=0.5806328058242798, max_ :hat 2.6284501552581787\n",
      "\n",
      "Epoch 98/100, loss=0.5779461860656738, max_ :hat 2.6279757022857666\n",
      "\n",
      "Epoch 99/100, loss=0.5752967596054077, max_ :hat 2.627408742904663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5753, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the encoder on a first pass\n",
    "model_example.encoder_fit(data_example[\"x\"], data_example[\"y\"], data_example[\"z\"], data_example[\"u\"], epochs=100, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    zhat, uhat = model_example.encoder(data_example[\"x\"], data_example[\"y\"], transform_response=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(data_example[\"z\"], zhat)\n",
    "plt.scatter(data_example[\"u\"], uhat)\n",
    "plt.plot([-5, 5], [-5, 5], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_loss(input, target, var_y, mask, sign=1):\n",
    "#     #return sign * torch.sum(input*target / torch.sqrt(var_y), dim=[1,2]).mean()\n",
    "#     return sign * torch.sum((input*target / torch.sqrt(var_y)) * mask)/torch.sum(torch.logical_not(mask)) + torch.log(var_y).mean()\n",
    "\n",
    "def evaluate_fit(input, target, mask):\n",
    "    with torch.no_grad():\n",
    "        return torch.sum(torch.pow((input - target)*mask,2))/torch.sum(~mask)\n",
    "    \n",
    "class OneLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, y, yhat, ys, yshat, mask):\n",
    "        \"\"\"Computes the loss. hat is recontructed y, ys is simulated\"\"\"\n",
    "        loss_sample = torch.sum(y * yhat * mask) / torch.sum(~mask)\n",
    "        loss_simulated = torch.sum(ys *  yshat * mask) / torch.sum(~mask)\n",
    "\n",
    "        return loss_sample - loss_simulated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GLLVM_longitudinal()\n",
    "data_true = data_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 1/100, loss_fit = 188.33, encoder_loss = 0.88, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 2/100, loss_fit = 567.12, encoder_loss = 0.64, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 3/100, loss_fit = 782.25, encoder_loss = 0.59, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 4/100, loss_fit = 972.14, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 5/100, loss_fit = 1955.58, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 6/100, loss_fit = 707.45, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 7/100, loss_fit = 1684.21, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 8/100, loss_fit = 1093.22, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 9/100, loss_fit = 1403.87, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 10/100, loss_fit = 1093.59, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 11/100, loss_fit = 962.96, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 12/100, loss_fit = 821.11, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 13/100, loss_fit = 851.47, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 14/100, loss_fit = 878.23, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 15/100, loss_fit = 935.61, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 16/100, loss_fit = 1170.33, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 17/100, loss_fit = 872.64, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 18/100, loss_fit = 947.83, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 19/100, loss_fit = 880.77, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 20/100, loss_fit = 641.02, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 21/100, loss_fit = 831.66, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 22/100, loss_fit = 925.27, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 23/100, loss_fit = 609.11, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 24/100, loss_fit = 1022.33, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 25/100, loss_fit = 757.63, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 26/100, loss_fit = 914.74, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 27/100, loss_fit = 898.82, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 28/100, loss_fit = 829.19, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 29/100, loss_fit = 649.68, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 30/100, loss_fit = 690.08, encoder_loss = 0.59, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 31/100, loss_fit = 680.40, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 32/100, loss_fit = 781.97, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 33/100, loss_fit = 878.04, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 34/100, loss_fit = 725.34, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 35/100, loss_fit = 777.51, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 36/100, loss_fit = 651.18, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 37/100, loss_fit = 650.29, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 38/100, loss_fit = 758.04, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 39/100, loss_fit = 569.55, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 40/100, loss_fit = 714.05, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 41/100, loss_fit = 633.81, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 42/100, loss_fit = 636.97, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 43/100, loss_fit = 812.28, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 44/100, loss_fit = 537.91, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 45/100, loss_fit = 830.71, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 46/100, loss_fit = 651.55, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 47/100, loss_fit = 706.97, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 48/100, loss_fit = 726.49, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 49/100, loss_fit = 678.82, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 50/100, loss_fit = 520.62, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 51/100, loss_fit = 594.23, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 52/100, loss_fit = 634.15, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 53/100, loss_fit = 495.08, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 54/100, loss_fit = 497.68, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 55/100, loss_fit = 540.71, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 56/100, loss_fit = 588.98, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 57/100, loss_fit = 772.44, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 58/100, loss_fit = 631.06, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 59/100, loss_fit = 488.61, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 60/100, loss_fit = 469.91, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 61/100, loss_fit = 655.65, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 62/100, loss_fit = 636.21, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 63/100, loss_fit = 692.72, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 64/100, loss_fit = 879.59, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 65/100, loss_fit = 744.27, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 66/100, loss_fit = 548.42, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 67/100, loss_fit = 752.06, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 68/100, loss_fit = 615.11, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 69/100, loss_fit = 814.73, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 70/100, loss_fit = 578.31, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 71/100, loss_fit = 664.26, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 72/100, loss_fit = 572.14, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 73/100, loss_fit = 710.00, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 74/100, loss_fit = 819.32, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 75/100, loss_fit = 665.33, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 76/100, loss_fit = 639.28, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 77/100, loss_fit = 846.86, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 78/100, loss_fit = 781.33, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 79/100, loss_fit = 574.42, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 80/100, loss_fit = 603.18, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 81/100, loss_fit = 689.95, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 82/100, loss_fit = 730.58, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 83/100, loss_fit = 619.73, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 84/100, loss_fit = 928.70, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 85/100, loss_fit = 686.61, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 86/100, loss_fit = 685.70, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 87/100, loss_fit = 597.21, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 88/100, loss_fit = 921.23, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 89/100, loss_fit = 790.44, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 90/100, loss_fit = 630.06, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 91/100, loss_fit = 633.46, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 92/100, loss_fit = 665.54, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 93/100, loss_fit = 995.41, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 94/100, loss_fit = 734.38, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 95/100, loss_fit = 597.15, encoder_loss = 0.62, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 96/100, loss_fit = 671.34, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 97/100, loss_fit = 683.79, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 98/100, loss_fit = 818.37, encoder_loss = 0.60, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 99/100, loss_fit = 692.23, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n",
      "max of data_sim: 20.0\n",
      "\n",
      "Epoch 100/100, loss_fit = 838.28, encoder_loss = 0.61, phi= 0.05000000074505806, var_u =1.0, var_y=1.0\n"
     ]
    }
   ],
   "source": [
    "criterion = OneLoss()\n",
    "learning_rate = 0.001\n",
    "max_gradient_value = .1\n",
    "optimizer = torch.optim.SGD(model.decoder.parameters(), lr=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "mseLoss = nn.MSELoss()\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(1, epochs +1):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "    # impute and sample\n",
    "    with torch.no_grad():\n",
    "        # data_true[\"y\"] = model.impute(data_true[\"x\"], data_true[\"y\"], mask=mask[\"y\"], nsteps=5)\n",
    "        # simulate data from the current parameter values, Unconditionally (!)\n",
    "        dat_sim = model.sample(n, x=data_true[\"x\"])\n",
    "        # compute the imputing values without the gradients\n",
    "        zhat_sample, uhat_sample = model.encoder(data_true[\"x\"], data_true[\"y\"], transform_response=True)\n",
    "        zhat_sim, uhat_sim = model.encoder(dat_sim[\"x\"], dat_sim[\"y\"], transform_response=True)\n",
    "\n",
    "    # train the encoder \n",
    "    encoder_loss = model.encoder_fit(dat_sim[\"x\"], dat_sim[\"y\"], dat_sim[\"z\"], dat_sim[\"u\"], epochs= 50 ) \n",
    "    \n",
    "    # compute the decoded value\n",
    "    yhat, linpar_sample = model.decoder(data_true[\"x\"], zhat_sample, uhat_sample)\n",
    "    yshat, linpar_sim = model.decoder(dat_sim[\"x\"], zhat_sim, uhat_sim)\n",
    "\n",
    "    print(f'max of data_sim: {torch.max(dat_sim[\"y\"])}')\n",
    "    # compute the loss\n",
    "    loss = criterion(linpar_sample, data_true[\"y\"],  linpar_sim, dat_sim[\"y\"], mask[\"y\"])\n",
    "\n",
    "    loss.backward(retain_graph=False) # we need to retain it because the loss function requires 2 passes through the decoder.. TODO: ACTUALLY THIS IS NOT THE BEHVAIOR I WANT, \n",
    "    with torch.no_grad():   \n",
    "        fit = mseLoss(yhat, data_true[\"y\"])\n",
    "\n",
    "    for param in model.decoder.parameters():\n",
    "        if param.grad is not None:\n",
    "            param.grad.clamp_(-max_gradient_value, max_gradient_value)\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch}/{epochs}, loss_fit = {fit.item():.2f}, encoder_loss = {encoder_loss.item():.2f}, phi= {model.phi.item()}, var_u ={model.var_u[0,0,0].item()}, var_y={model.decoder.var_y[0,0,0].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    zhat, uhat = model.encoder(data_true[\"x\"], data_true[\"y\"], transform_response=True)\n",
    "    yhat = model.decoder(data_true[\"x\"], zhat, uhat)\n",
    "\n",
    "plt.scatter(data_true[\"y\"], yhat)\n",
    "plt.plot([-10, 10], [-10, 10], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhat = zhat*-1\n",
    "plt.scatter(zhat, data_true[\"z\"])\n",
    "plt.plot([-2, 2], [-2,2], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 12 randomly selected Z\n",
    "index = np.random.choice(range(n), 12, replace=False)\n",
    "fig, axs = plt.subplots(3, 4)\n",
    "\n",
    "zhat= -gl.decoder.AR(dhat).detach()\n",
    "z_true= gl_true.decoder.AR(data_true[\"d\"]).detach()\n",
    "fig.suptitle(\"Ztrue vs Zest across time\")\n",
    "for i in range(12):\n",
    "    axs[i//4, i%4].plot(zhat[index[i],:,0]*-1)\n",
    "    axs[i//4, i%4].plot(z_true[index[i],:, 0], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_true = gl_true.decoder.parameters().__next__().detach().squeeze()\n",
    "par_est = gl.decoder.parameters().__next__() .detach().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-par_true, par_est)\n",
    "plt.plot([-2,2], [2, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details on tensor products calculations\n",
    "We now show the details on the tensor products, for instance for computing `xb @ wx`. `xb` is of size `(n, T, q)` and `wx` is of size `(T, q, p)`. We want a result of size `(n, T, p)`. First we add a dimension for `xb`:\n",
    "\n",
    "`xb.unsqueeze(2)` which yields a dimensions of `(n, T, 1, q)`\n",
    "\n",
    "which we then multiply by `wz`:\n",
    "\n",
    "`(n, T, 1, q) @ (1, q, p)` -> `(n, T, 1, p)`\n",
    "\n",
    "where the first dimension of `wx` has been broadcasted.\n",
    "\n",
    "Finally, we squeeze to obtain `(n, T, p)`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details on the computation of the forward pass\n",
    "\n",
    "The forward pass depends on $z_{it}$. According to the model, we have\n",
    "\n",
    "$$z_{i1} \\sim N(0,\\sigma_z^2).$$\n",
    "\n",
    "For identifiability reason, we have $z_{i1} = \\delta_{i1}$ where $\\delta_{i1}\\sim N(0,1)$\n",
    "\n",
    "and then\n",
    "\n",
    "$$z_{it+1} = \\phi z_{it} + \\delta{it}$$\n",
    "\n",
    "$$z_{i2} = \\phi \\delta_{i1} + \\delta_{i1}$$\n",
    "\n",
    "$$z_{i4} = \\phi z_{i3} + \\delta_{i3} \\Rightarrow z_{i3} = \\phi^2 \\delta_{i1} + \\phi \\delta_{i2} + \\delta_{i3}$$\n",
    "\n",
    "$$z_{it+1} = \\phi^{t-1}\\delta_{i1} + ... + \\phi \\delta_{it-1} + \\delta_{it}$$\n",
    "\n",
    "\n",
    "So we do not need in-place computations in the forward pass. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02379b91627ead677140c441995c323138285dea806245dca7a173ada35ac023"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

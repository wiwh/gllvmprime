{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assisted Deep GLLVM\n",
    "\n",
    "The idea is to assist the GLLVM estimation by using a pre-trained Neural network to estimate the MAP. Indeed, our theory states that it needs not be exactly the map, but an estimate of the center of the distribution. That's idea. \n",
    "\n",
    "We retain the properties of our estimator.\n",
    "\n",
    "__Our goal is thus here to just learn the MAP__, i.e. the function\n",
    "\n",
    "$$\n",
    "(Y, \\lambda) -> Z\n",
    "$$\n",
    "\n",
    "The key observation is the following:\n",
    "\n",
    "__Given the model parameters and Y_i, estimating Z_i is simply a GLM where Z_i takes the role of the coefficients to be estimated, and each element of Y_i as an independent observation, and each row of $\\Lambda$ is a covariate. (The covariates $X$ and their coefficient is simply an offset).\n",
    "\n",
    "That's it, really.\n",
    "\n",
    "So we want to learn an universal glm estimator where each \"observation\" can be of any type (say gamma, poisson, binomial, gaussien for now).\n",
    "\n",
    "* maximum dimension: q=10 latent variables (enough for now, but can be increased)\n",
    "* dimension is p x q  x k (num \"obs\", dim, band_dim)\n",
    "* where band dim include the offset, y, presence or absence of the variable (if q<10, some of them are \"off\"), as well as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 1.3345,  0.1706, -0.4414],\n",
      "        [ 1.4991, -0.4833, -1.4498],\n",
      "        [ 2.2045,  2.5709,  1.6691],\n",
      "        [ 0.3803,  0.2784, -0.2194],\n",
      "        [-0.8807, -0.1161,  0.6961],\n",
      "        [ 2.6167, -0.2041, -1.7944],\n",
      "        [-2.9218,  2.6049,  3.9884],\n",
      "        [-2.3329, -2.3463, -1.7143],\n",
      "        [ 5.9565, -2.2488, -4.1923],\n",
      "        [ 1.7812,  5.1165,  4.2327],\n",
      "        [ 2.0837, -2.3738, -3.3327],\n",
      "        [-2.7089,  2.4973,  4.2319],\n",
      "        [ 2.1300, -2.5197, -3.5582],\n",
      "        [ 2.3013, -1.4046, -1.7827],\n",
      "        [-0.7289,  2.4966,  2.9004],\n",
      "        [ 2.5978, -2.0063, -3.2621],\n",
      "        [-4.0039,  2.3573,  3.8864],\n",
      "        [ 3.0664, -5.2271, -5.5968],\n",
      "        [ 1.6981,  4.9455,  3.6317],\n",
      "        [ 2.2550, -0.7267, -2.0255],\n",
      "        [ 0.7498,  1.8427,  1.4452],\n",
      "        [-4.9837,  2.3109,  3.6470],\n",
      "        [-2.3599, -1.5001, -1.0567],\n",
      "        [-2.8974, -0.6060,  1.0404],\n",
      "        [-0.1621, -1.5871, -1.6179],\n",
      "        [-3.2741,  0.7124,  2.3289],\n",
      "        [ 2.5773, -0.7826, -2.2577],\n",
      "        [-0.2453,  1.2159,  1.9319],\n",
      "        [-2.8724,  0.7707,  1.4342],\n",
      "        [-2.9508, -0.8795, -0.0660],\n",
      "        [ 2.8562, -1.2566, -2.3614],\n",
      "        [-1.2978,  3.0866,  3.0285],\n",
      "        [ 4.1523, -3.2182, -4.5928],\n",
      "        [-1.6110,  2.9838,  3.2778],\n",
      "        [ 2.8891, -1.8745, -3.1453],\n",
      "        [ 0.2667,  3.5803,  3.3507],\n",
      "        [ 2.4319, -0.4957, -2.0110],\n",
      "        [-0.4673,  2.3518,  2.6104],\n",
      "        [ 1.8777, -1.8292, -2.3425],\n",
      "        [ 3.9579, -0.3839, -1.4719],\n",
      "        [ 2.2952,  1.8863,  0.5703],\n",
      "        [ 1.4635, -0.4137, -0.7744],\n",
      "        [-0.7702, -0.9798, -0.5452],\n",
      "        [ 2.1109, -1.8185, -2.4626],\n",
      "        [-0.2754,  1.3338,  2.2401],\n",
      "        [ 0.9709, -0.7946, -1.4684],\n",
      "        [ 0.2792,  1.6006,  1.4510],\n",
      "        [-1.2903,  2.1862,  1.8926],\n",
      "        [ 2.6360, -2.5315, -3.1082],\n",
      "        [-1.0593,  1.7908,  2.8074],\n",
      "        [-2.5370,  0.2792,  0.3894],\n",
      "        [-0.6830, -1.9776, -1.4422],\n",
      "        [-3.4705,  0.4417,  2.0297],\n",
      "        [ 1.8622, -2.5494, -3.4271],\n",
      "        [-5.2942,  3.2618,  5.7501],\n",
      "        [ 0.1381, -4.7260, -4.7513],\n",
      "        [-4.6660,  2.6780,  4.2392],\n",
      "        [-2.6524, -1.1591, -0.2748],\n",
      "        [-2.2093,  0.3735,  0.9715],\n",
      "        [-1.7714,  0.6799,  0.8570],\n",
      "        [-0.2835, -2.1561, -1.6281],\n",
      "        [ 2.4451, -0.6036, -1.2014],\n",
      "        [-1.3955,  0.5364,  1.1404],\n",
      "        [-1.8049,  0.5648,  1.0673],\n",
      "        [-6.8782,  1.4497,  3.1583],\n",
      "        [ 0.2865, -3.0047, -3.3306],\n",
      "        [-5.2583,  1.5854,  3.9568],\n",
      "        [ 1.8282, -2.0047, -2.5908],\n",
      "        [-0.3578,  1.1416,  1.6230],\n",
      "        [ 2.6192, -1.7593, -2.9598],\n",
      "        [ 1.3436, -0.1368,  0.2981],\n",
      "        [-1.8876,  2.5956,  2.6980],\n",
      "        [ 3.1579, -1.4450, -2.6448],\n",
      "        [ 2.1882,  0.1056, -0.1007],\n",
      "        [-3.9549,  4.1511,  4.9374],\n",
      "        [ 1.6354, -5.4808, -5.8422],\n",
      "        [-3.0326,  3.2158,  4.7916],\n",
      "        [-2.4494, -0.7045, -0.6005],\n",
      "        [-0.7255, -1.4556, -1.1591],\n",
      "        [-0.3230,  0.6562,  0.7239],\n",
      "        [ 1.3610, -1.8566, -1.8967],\n",
      "        [ 1.3560,  1.3426,  0.6138],\n",
      "        [ 0.6872,  0.6787,  0.4928],\n",
      "        [ 2.9926, -0.9600, -2.3358],\n",
      "        [ 0.8898,  0.4015,  0.2742],\n",
      "        [ 0.1437,  3.6400,  2.6738],\n",
      "        [ 2.7487, -2.9900, -3.7511],\n",
      "        [ 1.2148, -0.3798,  0.1712],\n",
      "        [-2.4452,  0.9597,  1.6361],\n",
      "        [-2.6776, -1.5454, -0.0487],\n",
      "        [-1.6979,  0.0382,  0.7530],\n",
      "        [-0.8739, -0.3164, -0.4015],\n",
      "        [-1.2477,  0.8004,  1.4830],\n",
      "        [-2.9456, -0.1226,  1.1948],\n",
      "        [-0.4600, -1.7155, -1.3241],\n",
      "        [ 2.6283, -0.2674, -1.0603],\n",
      "        [-1.4599,  4.0707,  3.9685],\n",
      "        [-0.3628, -0.7250, -0.7375],\n",
      "        [-1.9515,  1.3621,  1.9514]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VARModel(nn.Module):\n",
    "    def __init__(self, q):\n",
    "        super(VARModel, self).__init__()\n",
    "        self.q = q\n",
    "        \n",
    "        # Learnable autoregressive coefficient matrix A\n",
    "        self.A = nn.Parameter(torch.randn(q, q))\n",
    "        \n",
    "        # Learnable matrix L, from which the covariance matrix will be derived\n",
    "        self.L = nn.Parameter(torch.randn(q, q))\n",
    "        \n",
    "    def forward(self, timesteps, initial_state=None):\n",
    "        \"\"\"\n",
    "        Generate a vector autoregressive (VAR) Gaussian random variable through time.\n",
    "        \n",
    "        Args:\n",
    "        - timesteps (int): Number of time steps to generate.\n",
    "        - initial_state (torch.Tensor, optional): Initial state vector of shape (q,).\n",
    "        \n",
    "        Returns:\n",
    "        - torch.Tensor: Generated time series data of shape (timesteps, q).\n",
    "        \"\"\"\n",
    "        device = self.A.device\n",
    "        \n",
    "        # Compute the covariance matrix as L L^T\n",
    "        cov_matrix = self.L @ self.L.T\n",
    "        \n",
    "        # Initialize the time series data array\n",
    "        time_series = torch.zeros(timesteps, self.q).to(device)\n",
    "        \n",
    "        # If initial_state is not provided, initialize with zeros\n",
    "        if initial_state is None:\n",
    "            initial_state = torch.zeros(self.q).to(device)\n",
    "        \n",
    "        # Set the initial state\n",
    "        time_series[0] = initial_state\n",
    "        \n",
    "        # Generate the time series data\n",
    "        for t in range(1, timesteps):\n",
    "            noise = torch.distributions.MultivariateNormal(torch.zeros(self.q), cov_matrix).sample()\n",
    "            time_series[t] = self.A @ time_series[t-1] + noise\n",
    "        \n",
    "        return noise, time_series\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "q = 3  # Dimension of the multivariate time series\n",
    "timesteps = 100  # Number of time steps\n",
    "\n",
    "# Initialize the VAR model\n",
    "var_model = VARModel(q)\n",
    "\n",
    "# Generate the time series data\n",
    "time_series = var_model(timesteps)\n",
    "\n",
    "print(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Locate the parent directory and then the cousin directory\n",
    "current_dir = os.getcwd()\n",
    "gllvmprime_dir = os.path.join(current_dir, \"..\")\n",
    "\n",
    "# Add the cousin directory to the system path\n",
    "sys.path.append(gllvmprime_dir)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gllvmprime as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([190., 390.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.distributions.binomial import Binomial\n",
    "\n",
    "a = Binomial(torch.Tensor([1000]), torch.Tensor([.2, .4]))\n",
    "a.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sample' object has no attribute 'phi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m response_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m4\u001b[39m]} \u001b[38;5;66;03m# number of trials\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model_true \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mLongitudinalGLLVM(num_var, num_latent, num_covar, num_period, response_types, response_args)\n\u001b[0;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/gllvmprime/gllvm/../gllvmprime/longitudinal.py:293\u001b[0m, in \u001b[0;36mSample.forward\u001b[0;34m(self, x, n)\u001b[0m\n\u001b[1;32m    291\u001b[0m u \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((n, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting\u001b[38;5;241m.\u001b[39mp))\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_uvar))\n\u001b[1;32m    292\u001b[0m d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting\u001b[38;5;241m.\u001b[39mq))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 293\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAR\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m linpar, mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, z, u) \u001b[38;5;66;03m# decoder gives the expectation\u001b[39;00m\n\u001b[1;32m    297\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_response(mean)\n",
      "File \u001b[0;32m~/GitHub/gllvmprime/gllvm/../gllvmprime/longitudinal.py:327\u001b[0m, in \u001b[0;36mSample.AR\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    324\u001b[0m z \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 327\u001b[0m     z[:,t] \u001b[38;5;241m=\u001b[39m z[:,t] \u001b[38;5;241m+\u001b[39m z[:, t\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi\u001b[49m  \u001b[38;5;66;03m# we need to clone else the gradient wants to pass through it\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sample' object has no attribute 'phi'"
     ]
    }
   ],
   "source": [
    "num_obs = 1000\n",
    "num_var = 100\n",
    "num_latent = 2\n",
    "num_covar = 1\n",
    "num_period = 2\n",
    "response_types= {\"gaussian\":np.arange(100)}\n",
    "response_args = {\"binomial\":[4]} # number of trials\n",
    "\n",
    "model_true = gp.LongitudinalGLLVM(num_var, num_latent, num_covar, num_period, response_types, response_args)\n",
    "\n",
    "data = model_true.sample(x=None, n=num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_true.sample(x=None, n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 2])\n",
      "torch.Size([1000, 1000, 100])\n",
      "torch.Size([1000, 1, 2])\n",
      "torch.Size([1000, 1, 100])\n",
      "torch.Size([1000, 1000, 100])\n",
      "torch.Size([1000, 1000, 100])\n"
     ]
    }
   ],
   "source": [
    "for value in data.values():\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self Encoder(nn.Module):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted beta coefficients: tensor([[-0.0917,  0.1447, -0.1612,  0.0298,  0.0983],\n",
      "        [-0.0874,  0.1463, -0.1370,  0.0250,  0.1084],\n",
      "        [-0.0913,  0.1436, -0.1609,  0.0314,  0.0981],\n",
      "        [-0.0812,  0.1534, -0.1140,  0.0059,  0.1203]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class BetaEstimatorRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BetaEstimatorRNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.rnn(x)\n",
    "        hn = hn.squeeze(0)\n",
    "        beta_hat = self.fc(hn)\n",
    "        return beta_hat\n",
    "\n",
    "# Example dimensions (modify as needed)\n",
    "input_dim = 1  # Each element in x is a scalar\n",
    "hidden_dim = 50\n",
    "output_dim = 5  # Number of beta coefficients to predict\n",
    "\n",
    "# Create the model\n",
    "model = BetaEstimatorRNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Example input data\n",
    "batch_size = 4\n",
    "max_len = 10  # Maximum length of sequences in the batch\n",
    "x = torch.randn(batch_size, max_len, input_dim)  # Example batch of variable-length sequences\n",
    "y = torch.randn(batch_size, output_dim)  # Example batch of target beta values\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training step (simplified for illustration)\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "beta_hat = model(x)\n",
    "loss = criterion(beta_hat, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Predicted beta coefficients:\", beta_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR # scheduler\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class LongitudinalGLLVM(nn.Module):\n",
    "    def __init__(self, num_var, num_latent, num_covar, num_period, response_types, intercept=True):\n",
    "        super().__init__()\n",
    "        self.setting = {\n",
    "            \"p\":num_var, \n",
    "            \"q\":num_latent, \n",
    "            \"k\":num_covar, \n",
    "            \"T\":num_period,\n",
    "            'response_types': response_types,\n",
    "            'response_link': \n",
    "                {\n",
    "                'binary' : lambda x: torch.logit(x),\n",
    "                'ordinal': lambda x: torch.logit(x),\n",
    "                'counts': lambda x: torch.log(x)\n",
    "                },\n",
    "            'response_linkinv':\n",
    "                {\n",
    "                'binary': lambda x: 1/(1+torch.exp(-x)),\n",
    "                'ordinal': lambda x: 1/(1+torch.exp(-x)),\n",
    "                'counts': lambda x: torch.exp(x)\n",
    "                },\n",
    "            'response_transform':\n",
    "                {\n",
    "                'binary' : lambda x: 2*x - 1,\n",
    "                'ordinal': lambda x: 2*x - 1,\n",
    "                'counts': lambda x: torch.log(x+1)\n",
    "                },\n",
    "            \"intercept\": intercept\n",
    "        }\n",
    "\n",
    "        self.encoder = Encoder(self.setting)\n",
    "        self.decoder = Decoder(self.setting)\n",
    "        self.sample = Sample(self.decoder, self.setting)\n",
    "        self.optimizer = torch.optim.Adam(self.decoder.parameters(), lr=.1)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=10, gamma=.95)\n",
    "\n",
    "    \n",
    "    def plot_cov(self, what=\"linpar\", x=None):\n",
    "        data_sample = self.sample(x=x)\n",
    "        data =  data_sample[what].detach().view(n, -1).cpu().numpy()\n",
    "        cov_matrix = np.cov(data, rowvar=False)\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cov_matrix, annot=False, fmt='g')\n",
    "        plt.show()\n",
    "    \n",
    "    def set_learning_rates(self, lr_model = None, lr_encoder=None):\n",
    "        if lr_model is not None:\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = lr_model\n",
    "        \n",
    "        if lr_encoder is not None:\n",
    "            for param_group in self.encoder.optimizer.param_groups:\n",
    "                param_group['lr'] = lr_encoder\n",
    "        \n",
    "    def transform_responses(self, y):\n",
    "        y_transformed = torch.zeros_like(y)\n",
    "        with torch.no_grad():\n",
    "            for response_type, response_id in self.setting['response_types'].items():\n",
    "                y_transformed[:,:,response_id] = self.setting['response_transform'][response_type](y[:,:,response_id])\n",
    "        return y_transformed\n",
    "\n",
    "    \n",
    "    def fit(self, x, y, mask, epochs, lr_model=None, lr_encoder=None, phi_lb = -1, phi_ub = 1, varu_lb = 0.1, varu_ub=2):\n",
    "        \n",
    "        device = self.decoder.wz.device\n",
    "\n",
    "        self.set_learning_rates(lr_model, lr_encoder)\n",
    "\n",
    "        y_masked = y.clone()\n",
    "        y_masked[mask] = 0.5\n",
    "        criterion = MELoss(setting=self.setting)\n",
    "        mseLoss = MSELoss(setting=self.setting)\n",
    "        # create tensor dataset\n",
    "        losses = []\n",
    "        learning_rates = []\n",
    "        learning_rates_encoder = []\n",
    "        loading_values = []\n",
    "        intercept_values = []\n",
    "        coef_values = []\n",
    "\n",
    "\n",
    "        for epoch in range(1, epochs +1):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # impute and sample\n",
    "            with torch.no_grad():\n",
    "                # data_true[\"y\"] = model.impute(data_true[\"x\"], data_true[\"y\"], mask=mask[\"y\"], nsteps=5)\n",
    "                # simulate data from the current parameter values, Unconditionally (!)\n",
    "                data_sim = self.sample(x=x)\n",
    "                y_sim_masked = data_sim[\"y\"].clone()\n",
    "\n",
    "                # # TODO: Check imputation: this is waaaay better\n",
    "                y_masked[mask] = 0.5\n",
    "                y_sim_masked[mask] = 0.5\n",
    "\n",
    "                # y_masked = self.mean_impute(y=y_masked, mask=mask)\n",
    "                # y_sim_masked = self.mean_impute(y=y_sim_masked, mask=mask)\n",
    "\n",
    "                # y_masked = self.impute(x, y_masked, mask, nsteps=1)\n",
    "                # y_sim_masked = self.impute(x, y_sim_masked, mask, nsteps=1)\n",
    "\n",
    "                \n",
    "                # assert torch.eq(data_sim[\"x\"], x).all().item()\n",
    "\n",
    "                # compute the imputing values without the gradients\n",
    "                zhat_sample, uhat_sample = self.encoder(x, y_masked, transform_response=True)\n",
    "                zhat_sim, uhat_sim = self.encoder(data_sim[\"x\"], y_sim_masked, transform_response=True)\n",
    "\n",
    "\n",
    "            # train the encoder on the simulated data: importantly this needs to be done after the imputation to unwanted sample dependence\n",
    "            encoder_loss = self.encoder.fit(data_sim[\"x\"], data_sim[\"y\"], data_sim[\"z\"], data_sim[\"u\"],  epochs= 20) \n",
    "            \n",
    "            # compute the decoded value\n",
    "            linpar_sample, mean_sample = self.decoder(x, zhat_sample, uhat_sample)\n",
    "            linpar_sim, mean_sim = self.decoder(data_sim[\"x\"], zhat_sim, uhat_sim)\n",
    "\n",
    "            # # impute values\n",
    "            # data_sample[\"y\"] = model.impute(data_sample[\"x\"], data_sample[\"y\"], mask, nsteps=2)\n",
    "            # data_sim[\"y\"] = model.impute(data_sim[\"x\"], data_sim[\"y\"], mask, nsteps=2)\n",
    "\n",
    "            # model.decoder.wz.grad = mygrad\n",
    "            loss = criterion(y_masked, linpar_sample,  y_sim_masked, linpar_sim, mask=mask)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update nuisance parameters\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                self.sample.var_u.data = .8* self.sample.var_u.data + .2 * torch.var(uhat_sample) * (self.sample.var_u.data / torch.var(uhat_sim))\n",
    "                self.sample.phi.data = .8 * self.sample.phi.data + .2 * self.compute_autocorr(zhat_sample) * self.sample.phi.data / self.compute_autocorr(zhat_sim)\n",
    "\n",
    "                self.sample.phi.data = torch.clamp(self.sample.phi.data, phi_lb, phi_ub)\n",
    "                self.sample.var_u.data = torch.clamp(self.sample.var_u.data, varu_lb, varu_ub)\n",
    "\n",
    "                print(f'var_u: {self.sample.var_u}, phi: {self.sample.phi}')\n",
    "            \n",
    "\n",
    "\n",
    "            with torch.no_grad():   \n",
    "                fit = mseLoss(y_masked, mean_sample, mask)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            losses.append(fit.item())\n",
    "            learning_rates.append(self.optimizer.param_groups[0]['lr'])\n",
    "            learning_rates_encoder.append(self.encoder.optimizer.param_groups[0]['lr'])\n",
    "            loading_values.append(self.decoder.wz.clone().detach())\n",
    "            coef_values.append(self.decoder.wx.clone().detach())\n",
    "            intercept_values.append(self.decoder.bias.clone().detach())\n",
    "            print(f\"\\nEpoch {epoch}/{epochs}, loss_fit = {fit.item():.2f}, encoder_loss = {encoder_loss.item():.2f}.\")\n",
    "\n",
    "        saved = {\n",
    "            \"losses\": losses,\n",
    "            \"learning_rates\": learning_rates,\n",
    "            \"learning_rates_encoder\": learning_rates_encoder,\n",
    "            \"loading_values\": loading_values,\n",
    "            \"coef_values\": coef_values,\n",
    "            \"intercept_values\": intercept_values\n",
    "        }\n",
    "\n",
    "        return saved\n",
    "\n",
    "\n",
    "    def impute(self, x, y, mask, nsteps=10):\n",
    "        \"\"\" Impute the missing values provided by the mask (True is missing) and return x imputed\"\"\"\n",
    "        for _ in range(nsteps):\n",
    "            z, u = self.encoder(x,y, transform_response = True)\n",
    "            _, mean = self.decoder(x,z,u)\n",
    "            y[mask] = mean[mask]\n",
    "        return y\n",
    "    \n",
    "    def mean_impute(self, y, mask):\n",
    "        var_mean = torch.mean(y, dim=2).unsqueeze(2)\n",
    "        ymean = torch.ones_like(y) * var_mean\n",
    "        y[mask] = ymean[mask]\n",
    "        return y\n",
    "\n",
    "    def compute_autocorr(self, z):\n",
    "        # Compute the sample autocovariance and autocorrelation\n",
    "        autocovariance = torch.mean((z[:, 1:] - torch.mean(z[:, 1:])) * (z[:, :-1] - torch.mean(z[:, :-1])), dim=1)\n",
    "        autocorrelation = autocovariance / torch.var(z[:, :-1])\n",
    "\n",
    "        # Estimate phi using the autocorrelation formula for AR(1)\n",
    "        phi = torch.mean(autocorrelation)\n",
    "\n",
    "        return phi\n",
    "\n",
    "class Sample(nn.Module):\n",
    "    def __init__(self, decoder, setting):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder\n",
    "        self.setting = setting\n",
    "        self.phi = nn.Parameter(torch.ones(1) * .8)#.detach() # we do not update it using backprop, but still define as a nn.Parameter to easily change between devices using nn.Module.to()\n",
    "        self.var_u = nn.Parameter(torch.ones(1) * 1.0)#.detach()\n",
    "    \n",
    "    def forward(self, x, n=None):\n",
    "        device = self.phi.device\n",
    "        with torch.no_grad():\n",
    "            if x is None:\n",
    "                Warning(\"x was set to None for sampling. X is usually fixed. Are you sure you want to sample x?\")\n",
    "                x = torch.randn((n, self.setting['T'], self.setting['k']-1)).to(device)\n",
    "                # Add intercepts and time information\n",
    "                time_data = torch.from_numpy(np.linspace(0,4,self.setting['T'])).float().expand(x.shape[0], -1).unsqueeze(2).to(device)\n",
    "                x = torch.cat([x, time_data], dim=2)\n",
    "            \n",
    "            n = x.shape[0]\n",
    "\n",
    "            u = torch.randn((n, 1, self.setting['p'])).to(device) * torch.sqrt(self.var_u)\n",
    "            d = torch.randn((n, self.setting['T'], self.setting['q'])).to(device)\n",
    "            z = self.AR(d)\n",
    "\n",
    "            linpar, mean = self.decoder(x, z, u) # decoder gives the expectation\n",
    "\n",
    "            y = self.sample_response(mean)\n",
    "\n",
    "            return {\"x\":x, \"y\":y, \"z\":z, \"u\":u, \"linpar\":linpar, \"mean\":mean}\n",
    "\n",
    "    def sample_response(self, mean):\n",
    "        device = self.phi.device\n",
    "        y = torch.zeros_like(mean).to(device)\n",
    "        for response_type, response_id in self.setting['response_types'].items():\n",
    "            if response_type == \"binary\":\n",
    "                y[:,:,response_id] = torch.bernoulli(mean[:,:,response_id]).to(device)\n",
    "            elif response_type == \"ordinal\":\n",
    "                cum_probs = mean[:,:,response_id]\n",
    "                # draw one uniform for the whole vector\n",
    "                random = torch.rand((*cum_probs.shape[0:2], 1)).to(device)\n",
    "                # compare with the cumulative probabilities\n",
    "                ordinal = torch.sum(random > cum_probs, dim=2)\n",
    "                ordinal = torch.nn.functional.one_hot(ordinal).squeeze().float()\n",
    "                ordinal = ordinal[:,:,1:] # discard the first column of the one_hot encoding, as it is superfluous (as a 0)\n",
    "                y[:,:,response_id] = ordinal\n",
    "            elif response_type == \"counts\":\n",
    "                y[:,:,response_id] = torch.poisson(mean[:,:,response_id])\n",
    "        return y\n",
    "\n",
    "    def AR(self, d):\n",
    "        z = d.clone()\n",
    "\n",
    "        for t in range(1, z.shape[1]):\n",
    "            z[:,t] = z[:,t] + z[:, t-1].clone() * self.phi  # we need to clone else the gradient wants to pass through it\n",
    "        return z\n",
    "                \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    # Yields the expectation\n",
    "    def __init__(self, setting):\n",
    "        super().__init__()\n",
    "        self.setting = setting\n",
    "        # decoder part (our parameters of interest)\n",
    "        self.wz = nn.Parameter(torch.randn((self.setting['q'], self.setting['p'])) * 1.2)\n",
    "        self.wx = nn.Parameter(torch.randn((1, self.setting['k'], self.setting['p']))* .2) # Measurement invariance!\n",
    "        self.bias = nn.Parameter(torch.zeros((1, 1, self.setting['p']))* .2) # Measurement invariance!\n",
    "\n",
    "    # decoding (computing the conditional mean)\n",
    "    def forward(self, x, z, u):\n",
    "\n",
    "        xwx = (x.unsqueeze(2) @ self.wx).squeeze() # see section \"details of tensorproducts\"\n",
    "        zwz = (z.unsqueeze(2) @ self.wz).squeeze()\n",
    "        # for the ordinal variables:\n",
    "\n",
    "        if self.setting['intercept']:\n",
    "            linpar = self.bias + xwx + zwz + u \n",
    "        else:\n",
    "            linpar = xwx + zwz + u \n",
    "\n",
    "\n",
    "        # Apply the inverse link to get the conditional expectation\n",
    "        mean  = torch.zeros_like(linpar)\n",
    "        for response_type, response_id in self.setting['response_types'].items():\n",
    "            mean[:,:,response_id] = self.setting['response_linkinv'][response_type](linpar[:,:,response_id])\n",
    "        # Transform the \n",
    "        return linpar, mean\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, setting):\n",
    "        super().__init__()\n",
    "        self.setting=setting\n",
    "        # encoder part\n",
    "        # input dimension is (p+k) (responses + covariates)\n",
    "        # output dimension is q+p (one latent )\n",
    "        input_size = self.setting['p'] + self.setting['k']\n",
    "        hidden_size = (self.setting['p'] + self.setting['q']) * 5\n",
    "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features = hidden_size, out_features = hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = hidden_size, out_features = hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # fully connected layers for Z and U\n",
    "        self.fc_Z = nn.Sequential(\n",
    "            nn.Linear(in_features = hidden_size, out_features = hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = hidden_size, out_features = hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = hidden_size, out_features = self.setting['q']),\n",
    "        )\n",
    "\n",
    "        self.fc_U = nn.Sequential(\n",
    "            nn.Linear(in_features = hidden_size, out_features = hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = hidden_size, out_features = hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features = self.setting['p'])\n",
    "        )\n",
    "\n",
    "        self.optimizer =  torch.optim.Adam(self.parameters(), lr=.01)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=100, gamma=.95)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    \n",
    "    def forward(self, x, y, transform_response = False):\n",
    "        # Initialize hidden state\n",
    "\n",
    "        # pass the input through the RNN\n",
    "        if transform_response:\n",
    "            y_transformed = torch.zeros_like(y)\n",
    "            with torch.no_grad():\n",
    "                for response_type, response_id in self.setting['response_types'].items():\n",
    "                    y_transformed[:,:,response_id] = self.setting['response_transform'][response_type](y[:,:,response_id])\n",
    "        else:\n",
    "            y_transformed = y\n",
    "\n",
    "        xy = torch.cat([x, y_transformed], dim=2)\n",
    "        rnn_out, _ = self.rnn(xy)\n",
    "        out = self.fc(rnn_out)\n",
    "        z_pred = self.fc_Z(out)\n",
    "        u_pred = self.fc_U(out[:, -1, :]).unsqueeze(1)\n",
    "        return z_pred, u_pred\n",
    "    \n",
    "    def fit(self, x, y, z, u, epochs = 100, verbose = False):\n",
    "        y = y.clone()\n",
    "        with torch.no_grad():\n",
    "            for response_type, response_id in self.setting['response_types'].items():\n",
    "                y[:,:,response_id] = self.setting['response_transform'][response_type](y[:,:,response_id])\n",
    "        # Fit the encoder\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            z_pred, u_pred = self(x, y, transform_response = False)\n",
    "\n",
    "            loss = self.loss(z_pred, z) + self.loss(u_pred, u)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\nEpoch {epoch}/{epochs}, loss={loss}\")\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def plot(self, x, y, z, u):\n",
    "        with torch.no_grad():\n",
    "            z_pred, u_pred = self(x, y, transform_response = True)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "        ax1.scatter(z, z_pred)\n",
    "        ax1.set_xlabel('Z True')\n",
    "        ax1.set_ylabel('Z Pred')\n",
    "        ax1.set_title('Encoded values of Z')\n",
    "        ax1.plot(ax1.get_xlim(), ax1.get_ylim(), ls=\"--\", color=\"red\")\n",
    "\n",
    "        ax2.scatter(u, u_pred)\n",
    "        ax2.set_xlabel('U True')\n",
    "        ax2.set_ylabel('U Pred')\n",
    "        ax2.set_title('Encoded values of U')\n",
    "        ax2.plot(ax2.get_xlim(), ax2.get_ylim(), ls=\"--\", color=\"red\")\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self, setting):\n",
    "        super().__init__()\n",
    "        self.setting = setting\n",
    "\n",
    "    def forward(self, y, mean, mask=None):\n",
    "        \"\"\"Computes the fit loss.\"\"\"\n",
    "        if mask is not None:\n",
    "            return torch.sum(torch.pow(y - mean, 2) * ~mask) / torch.sum(~mask)\n",
    "        else:\n",
    "            return torch.mean(torch.pow(y - mean, 2))\n",
    "\n",
    "class MELoss(nn.Module):\n",
    "    def __init__(self, setting):\n",
    "        super().__init__()\n",
    "        self.setting = setting\n",
    "    \n",
    "    def forward(self, y, linpar, ys, linpars, mask=None):\n",
    "        \"\"\"Computes the loss. hat is recontructed y, ys is simulated\"\"\"\n",
    "        y_transformed = torch.zeros_like(y)\n",
    "        ys_transformed = torch.zeros_like(ys)\n",
    "        with torch.no_grad():\n",
    "            for response_type, response_id in self.setting['response_types'].items():\n",
    "                y_transformed[:,:,response_id] = self.setting['response_transform'][response_type](y[:,:,response_id])\n",
    "                ys_transformed[:,:,response_id] = self.setting['response_transform'][response_type](ys[:,:,response_id])\n",
    "\n",
    "\n",
    "        if mask is not None:\n",
    "            return -torch.sum(y_transformed* linpar * ~mask - ys_transformed * linpars* ~mask)/y.shape[0]\n",
    "        else:\n",
    "            return -torch.sum(y_transformed* linpar - ys_transformed * linpars) / y.shape[0]\n",
    "        # return torch.mean(torch.pow(y-linpar, 2) - torch.pow(ys - linpars, 2))\n",
    "        # loss = torch.mean(y.T @ linpar - ys.T @linpars)/y.shape[0]\n",
    "        # return loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
